{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28d8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# from geofeather.pygeos import to_geofeather, from_geofeather\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "#import pygeos\n",
    "from rasterstats import zonal_stats\n",
    "from scipy.stats import spearmanr\n",
    "import shapely\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely import wkb\n",
    "from shapely.wkb import loads as from_wkb\n",
    "\n",
    "import rasterio\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.windows import Window\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "import fiona\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import reproject\n",
    "from rasterio.enums import Resampling as ResamplingEnums\n",
    "from rasterio.features import rasterize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4ef57",
   "metadata": {},
   "source": [
    "# Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91129ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tiling(input_path, tile_size, overlap, pad_value):\n",
    "    \"\"\"\n",
    "    Generator that yields raster tiles in-memory, with padding.\n",
    "\n",
    "    Args:\n",
    "        input_path (str): Path to input GeoTIFF.\n",
    "        tile_size (tuple): (width, height) of each tile in pixels.\n",
    "        overlap (tuple): (x_overlap, y_overlap) in pixels.\n",
    "        pad_value (int or float): Value used to pad edge tiles.\n",
    "\n",
    "    Yields:\n",
    "        dict: {\n",
    "            \"data\": np.ndarray (bands, height, width),\n",
    "            \"transform\": Affine transform of the tile,\n",
    "            \"indices\": (top, left) pixel coordinates in source\n",
    "        }\n",
    "    \"\"\"\n",
    "    tile_width, tile_height = tile_size\n",
    "    overlap_x, overlap_y = overlap\n",
    "\n",
    "    with rasterio.open(input_path) as src:\n",
    "        width, height = src.width, src.height\n",
    "        num_bands = src.count\n",
    "        step_x = tile_width - overlap_x\n",
    "        step_y = tile_height - overlap_y\n",
    "\n",
    "        for top in range(0, height, step_y):\n",
    "            for left in range(0, width, step_x):\n",
    "                win_width = min(tile_width, width - left)\n",
    "                win_height = min(tile_height, height - top)\n",
    "                window = Window(left, top, win_width, win_height)\n",
    "                transform = src.window_transform(window)\n",
    "\n",
    "                data = src.read(window=window)\n",
    "\n",
    "                if win_width < tile_width or win_height < tile_height:\n",
    "                    padded = np.full((num_bands, tile_height, tile_width), pad_value, dtype=data.dtype)\n",
    "                    padded[:, :win_height, :win_width] = data\n",
    "                    data = padded\n",
    "\n",
    "                yield {\n",
    "                    \"data\": data,\n",
    "                    \"transform\": transform,\n",
    "                    \"indices\": (top, left)\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa76a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object tiling at 0x000002D801E5A5A0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GDP tiles\n",
    "gdp_dates_2030 = (\"GDP2030_025_ssp1_clipped\", \"GDP2030_025_ssp2_clipped\", \"GDP2030_025_ssp3_clipped\", \"GDP2030_025_ssp4_clipped\", \"GDP2030_025_ssp5_clipped\")\n",
    "gdp_dates_2050 = (\"GDP2050_025_ssp1_clipped\", \"GDP2050_025_ssp2_clipped\", \"GDP2050_025_ssp3_clipped\", \"GDP2050_025_ssp4_clipped\", \"GDP2050_025_ssp5_clipped\")\n",
    "gdp_dates_2100 = (\"GDP2100_025_ssp1_clipped\", \"GDP2100_025_ssp2_clipped\", \"GDP2100_025_ssp3_clipped\", \"GDP2100_025_ssp4_clipped\", \"GDP2100_025_ssp5_clipped\")\n",
    "\n",
    "\n",
    "tiling(\n",
    "    input_path=\"GDP_clipped_files_025d\\GDP2030__025_ssp1_clipped.tif\",\n",
    "    tile_size=(64, 64),\n",
    "    overlap=(0,0), \n",
    "    pad_value=0\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a233926c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b06926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c82f53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce3c0fc6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff8b46",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815058f",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class InfrastructureDataset(Dataset):\n",
    "    def __init__(self, input_raster_path, label_raster_path,\n",
    "                 tile_size=(64, 64), overlap=(0, 0), pad_value=0, transform=None):\n",
    "        self.input_raster_path = input_raster_path\n",
    "        self.label_raster_path = label_raster_path\n",
    "        self.tile_size = tile_size\n",
    "        self.overlap = overlap\n",
    "        self.pad_value = pad_value\n",
    "        self.transform = transform\n",
    "\n",
    "        # Precompute tile indices\n",
    "        self.tile_indices = []\n",
    "        with rasterio.open(self.input_raster_path) as src:\n",
    "            self.width, self.height = src.width, src.height\n",
    "            self.num_bands = src.count\n",
    "            step_x = tile_size[0] - overlap[0]\n",
    "            step_y = tile_size[1] - overlap[1]\n",
    "\n",
    "            for top in range(0, self.height, step_y):\n",
    "                for left in range(0, self.width, step_x):\n",
    "                    self.tile_indices.append((top, left))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        top, left = self.tile_indices[idx]\n",
    "        tile_width, tile_height = self.tile_size\n",
    "\n",
    "        # Read input tile\n",
    "        with rasterio.open(self.input_raster_path) as src:\n",
    "            window = Window(left, top, tile_width, tile_height)\n",
    "            input_tile = src.read(window=window)\n",
    "\n",
    "            if input_tile.shape[1] < tile_height or input_tile.shape[2] < tile_width:\n",
    "                padded = np.full((self.num_bands, tile_height, tile_width), self.pad_value, dtype=input_tile.dtype)\n",
    "                padded[:, :input_tile.shape[1], :input_tile.shape[2]] = input_tile\n",
    "                input_tile = padded\n",
    "\n",
    "        # Read label tile (single-band)\n",
    "        with rasterio.open(self.label_raster_path) as lbl_src:\n",
    "            label_tile = lbl_src.read(1, window=window)\n",
    "\n",
    "            if label_tile.shape[0] < tile_height or label_tile.shape[1] < tile_width:\n",
    "                padded_label = np.full((tile_height, tile_width), self.pad_value, dtype=label_tile.dtype)\n",
    "                padded_label[:label_tile.shape[0], :label_tile.shape[1]] = label_tile\n",
    "                label_tile = padded_label\n",
    "\n",
    "        if self.transform:\n",
    "            input_tile, label_tile = self.transform(input_tile, label_tile)\n",
    "\n",
    "        return torch.tensor(input_tile, dtype=torch.float32), torch.tensor(label_tile, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9f88b96",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "dataset = InfrastructureDataset(\n",
    "    input_raster_path=\"cisi_index_pop_all_years.tif\",       # input: predictor\n",
    "    label_raster_path=\"CISI_label_file_025.tif\",          # label: infrastructure presence in 2020\n",
    "    tile_size=(64, 64),\n",
    "    overlap=(0, 0),\n",
    "    pad_value=0\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67948c",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # downsample\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, out_channels, 1)  # output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = F.interpolate(x, scale_factor=2, mode='bilinear', align_corners=False)  # upsample\n",
    "        x = self.decoder(x)\n",
    "        return x  # Output: [B, out_channels, H, W]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d5d9f5",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Training setup\n",
    "# select model\n",
    "model = SimpleCNN(in_channels=1, out_channels=1)  # Adjust in_channels if you have more bands\n",
    "\n",
    "# move model to device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# loss function (regression)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# define optimizer\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81852d76",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def train(model, loader, criterion, optimizer, num_epochs=10, device=\"cpu\"):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for inputs, targets in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device).unsqueeze(1).float()  # [B, 1, H, W]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss / len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1a7c3fb",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Loss: inf\n",
      "Epoch 2/20 - Loss: inf\n",
      "Epoch 3/20 - Loss: inf\n",
      "Epoch 4/20 - Loss: inf\n",
      "Epoch 5/20 - Loss: inf\n",
      "Epoch 6/20 - Loss: inf\n",
      "Epoch 7/20 - Loss: inf\n",
      "Epoch 8/20 - Loss: inf\n",
      "Epoch 9/20 - Loss: inf\n",
      "Epoch 10/20 - Loss: inf\n",
      "Epoch 11/20 - Loss: inf\n",
      "Epoch 12/20 - Loss: inf\n",
      "Epoch 13/20 - Loss: inf\n",
      "Epoch 14/20 - Loss: inf\n",
      "Epoch 15/20 - Loss: inf\n",
      "Epoch 16/20 - Loss: inf\n",
      "Epoch 17/20 - Loss: inf\n",
      "Epoch 18/20 - Loss: inf\n",
      "Epoch 19/20 - Loss: inf\n",
      "Epoch 20/20 - Loss: inf\n"
     ]
    }
   ],
   "source": [
    "# Run the training model\n",
    "train(model, loader, criterion, optimizer, num_epochs=20, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a6e5640",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input min/max: 0.0 0.7352721095085144\n",
      "Label min/max: -9223372036854775808 0\n"
     ]
    }
   ],
   "source": [
    "for x, y in loader:\n",
    "    print(\"Input min/max:\", x.min().item(), x.max().item())\n",
    "    print(\"Label min/max:\", y.min().item(), y.max().item())\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79b1b5",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac9f9d",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
