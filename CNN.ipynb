{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8eaa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchgeo in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: rasterio in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: segmentation-models-pytorch in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: einops>=0.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (0.8.1)\n",
      "Requirement already satisfied: fiona>=1.8.22 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.10.1)\n",
      "Requirement already satisfied: kornia>=0.7.4 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (0.8.1)\n",
      "Requirement already satisfied: lightly!=1.4.26,>=1.4.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.5.21)\n",
      "Requirement already satisfied: lightning!=2.3.*,!=2.5.0,>=2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.5.1.post0)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (3.8.4)\n",
      "Requirement already satisfied: pandas>=1.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (2.3.3)\n",
      "Requirement already satisfied: pyproj>=3.4 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (3.7.1)\n",
      "Requirement already satisfied: rtree>=1.0.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.4.0)\n",
      "Requirement already satisfied: shapely>=1.8.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (2.0.7)\n",
      "Requirement already satisfied: timm>=0.9.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.0.15)\n",
      "Requirement already satisfied: torchmetrics>=1.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.7.2)\n",
      "Requirement already satisfied: affine in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (23.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (2024.6.2)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: click-plugins in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (0.33.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from click>=4.0->rasterio) (0.4.6)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\n",
      "Requirement already satisfied: kornia_rs>=0.1.9 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kornia>=0.7.4->torchgeo) (0.1.9)\n",
      "Requirement already satisfied: hydra-core>=1.0.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (1.3.2)\n",
      "Requirement already satisfied: lightly_utils~=0.0.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (0.0.2)\n",
      "Requirement already satisfied: python_dateutil>=2.5.3 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.11.6)\n",
      "Requirement already satisfied: pytorch_lightning>=1.0.4 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.5.1.post0)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.2.2)\n",
      "Requirement already satisfied: aenum>=3.1.11 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (3.1.16)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.14.3)\n",
      "Requirement already satisfied: jsonargparse<5.0,>=4.27.7 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (4.40.0)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.2.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.3.0)\n",
      "Requirement already satisfied: rich<14.0,>=12.3.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (13.7.1)\n",
      "Requirement already satisfied: tensorboardX<3.0,>=2.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.6.4)\n",
      "Requirement already satisfied: bitsandbytes<1.0,>=0.45.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.46.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.6->torchgeo) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.6->torchgeo) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.6->torchgeo) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.6->torchgeo) (1.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.5->torchgeo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.5->torchgeo) (2024.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (3.12.12)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hydra-core>=1.0.0->lightly!=1.4.26,>=1.4.5->torchgeo) (4.9.3)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.16)\n",
      "Requirement already satisfied: typeshed-client>=2.3.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning-utilities<2.0,>=0.10.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (70.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=1.10.5->lightly!=1.4.26,>=1.4.5->torchgeo) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.17.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (5.29.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.20.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.1.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typeshed-client>=2.3.0->jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (6.5.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# installing\n",
    "!pip install torch torchvision torchgeo rasterio segmentation-models-pytorch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "434fa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TorchGeo imports\n",
    "from torchgeo.datasets import RasterDataset\n",
    "try:\n",
    "    from torchgeo.datasets import stack_samples  # newer\n",
    "except Exception:\n",
    "    from torchgeo.datasets.utils import stack_samples  # older\n",
    "\n",
    "try:\n",
    "    from torchgeo.datasets.geo import IntersectionDataset\n",
    "except Exception:\n",
    "    from torchgeo.datasets import IntersectionDataset\n",
    "\n",
    "from torchgeo.samplers import GridGeoSampler, RandomGeoSampler\n",
    "\n",
    "# U-Net backbone (Segmentation Models PyTorch)\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8adb70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stack three single-band rasters into one 3-band GeoTIFF\n",
    "# in_dir  = Path(\"READY_data/inputs\")\n",
    "# out_mb  = in_dir / \"historic_3band_025deg.tif\"\n",
    "\n",
    "# in_lc   = in_dir / \"2018_landcover_aligned_025deg.tif\"\n",
    "# in_gdp  = in_dir / \"2019_gdp_aligned_025deg.tif\"\n",
    "# in_pop  = in_dir / \"2020_pop_aligned_025deg.tif\"\n",
    "\n",
    "# with rasterio.open(in_lc) as src_lc, \\\n",
    "#      rasterio.open(in_gdp) as src_gdp, \\\n",
    "#      rasterio.open(in_pop) as src_pop:\n",
    "\n",
    "#     # sanity checks\n",
    "#     assert src_lc.crs == src_gdp.crs == src_pop.crs, \"CRS mismatch\"\n",
    "#     assert src_lc.transform == src_gdp.transform == src_pop.transform, \"transform mismatch\"\n",
    "#     assert (src_lc.width, src_lc.height) == (src_gdp.width, src_gdp.height) == (src_pop.width, src_pop.height), \"size mismatch\"\n",
    "\n",
    "#     lc  = src_lc.read(1)\n",
    "#     gdp = src_gdp.read(1)\n",
    "#     pop = src_pop.read(1)\n",
    "\n",
    "#     arr = np.stack([lc, gdp, pop], axis=0).astype(np.float32)  # (3, H, W)\n",
    "\n",
    "#     profile = src_lc.profile\n",
    "#     profile.update(count=3, dtype=\"float32\", nodata=np.nan)\n",
    "\n",
    "#     with rasterio.open(out_mb, \"w\", **profile) as dst:\n",
    "#         dst.write(arr)\n",
    "#         dst.set_band_description(1, \"landcover\")\n",
    "#         dst.set_band_description(2, \"gdp\")\n",
    "#         dst.set_band_description(3, \"pop\")\n",
    "\n",
    "# print(\"Wrote:\", out_mb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573a0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick inspection\n",
    "# import rasterio\n",
    "# from pathlib import Path\n",
    "\n",
    "# path = Path(\"READY_data/inputs/historic_3band_025deg.tif\")\n",
    "# with rasterio.open(path) as src:\n",
    "#     print(\"Bands:\", src.count)            # expect 3\n",
    "#     print(\"Size :\", src.width, \"x\", src.height)\n",
    "#     print(\"CRS  :\", src.crs)\n",
    "#     print(\"Desc :\", src.descriptions)     # ('landcover','gdp','pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fa0211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "class Args:\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.in_dir = \"READY_data/inputs\"\n",
    "args.lab_dir = \"READY_data/labels\"\n",
    "args.out_dir = \"checkpoints\"\n",
    "\n",
    "args.patch = 64\n",
    "args.train_windows = 500\n",
    "args.val_stride_frac = 1.0\n",
    "args.batch = 4\n",
    "args.workers = 0\n",
    "\n",
    "args.epochs = 50\n",
    "args.lr = 3e-4\n",
    "args.wd = 1e-2\n",
    "args.huber_delta = 0.5\n",
    "args.backbone = \"resnet34\"\n",
    "args.amp = True\n",
    "\n",
    "# ðŸ‘‡ add this line to fix the NaN normalization issue\n",
    "args.use_quick_norm = True # was False; now compute train-only mean/std\n",
    "args.norm_batches = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc217e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "class InputsDataset(RasterDataset):\n",
    "    \"\"\"Multi-band inputs (e.g., population, GDP, land-use) as aligned GeoTIFFs.\"\"\"\n",
    "    filename_glob = \"historic_3band_025deg.tif\"  # <â€” only the multiband file\n",
    "    is_image = True\n",
    "\n",
    "class LabelsDataset(RasterDataset):\n",
    "    \"\"\"\n",
    "    Single-band continuous target (e.g., CISI scaled to [0,1]).\n",
    "    Use float32 for continuous targets.\n",
    "    \"\"\"\n",
    "    filename_glob = \"2024_CISI_025deg.tif\"   # your label stays as before (single band)\n",
    "    is_image = False\n",
    "    dtype = torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20036813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization & Loss\n",
    "class ChannelWiseNormalize(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super().__init__()\n",
    "        m = torch.as_tensor(mean).view(1, -1, 1, 1)\n",
    "        s = torch.as_tensor(std).view(1, -1, 1, 1)\n",
    "        self.register_buffer(\"mean\", m.float())\n",
    "        self.register_buffer(\"std\", s.float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "\n",
    "class MaskedHuber(nn.Module):\n",
    "    \"\"\"Huber regression loss that ignores NaN or masked values.\"\"\"\n",
    "    def __init__(self, delta=0.5):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, pred, target, mask=None):\n",
    "        if mask is None:\n",
    "            mask = torch.isfinite(target)\n",
    "        mask = mask.float()\n",
    "\n",
    "        diff = pred - target\n",
    "        abs_diff = diff.abs()\n",
    "        delta = torch.tensor(self.delta, device=pred.device)\n",
    "        quadratic = torch.minimum(abs_diff, delta)\n",
    "        loss = 0.5 * quadratic**2 + delta * (abs_diff - quadratic) - 0.5 * (delta**2)\n",
    "        loss = loss * mask\n",
    "        denom = mask.sum().clamp_min(1.0)\n",
    "        return loss.sum() / denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53c49b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean/std stats block\n",
    "def quick_channel_stats(train_loader, in_ch, norm_batches):\n",
    "    \"\"\"Rough channel-wise mean/std over a few TRAIN batches (NaN-safe).\"\"\"\n",
    "    running_mean = torch.zeros(in_ch, dtype=torch.float64)\n",
    "    running_m2   = torch.zeros(in_ch, dtype=torch.float64)  # for variance via Welford\n",
    "    count        = torch.zeros(in_ch, dtype=torch.float64)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            xb = batch[\"image\"].float()  # (B,C,H,W)\n",
    "            xb = torch.nan_to_num(xb, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            B, C, H, W = xb.shape\n",
    "            xb = xb.view(B, C, -1)\n",
    "\n",
    "            # per-channel stats over all pixels in the batch\n",
    "            batch_sum   = xb.sum(dim=(0, 2)).double()\n",
    "            batch_count = torch.full((C,), B*H*W, dtype=torch.float64)\n",
    "            batch_mean  = batch_sum / batch_count\n",
    "\n",
    "            # update running mean and M2 (per channel)\n",
    "            delta = batch_mean - running_mean / torch.clamp(count, min=1.0)\n",
    "            running_mean += batch_sum\n",
    "            count        += batch_count\n",
    "            # recompute mean after merging\n",
    "            new_mean = running_mean / torch.clamp(count, min=1.0)\n",
    "\n",
    "            # approximate M2 by accumulating squared diffs within batch (cheap)\n",
    "            diffs = (xb.double() - batch_mean.view(1, C, 1))**2\n",
    "            running_m2 += diffs.sum(dim=(0, 2))\n",
    "\n",
    "            # move on\n",
    "            if i + 1 >= norm_batches:\n",
    "                break\n",
    "\n",
    "    mean = (running_mean / torch.clamp(count, min=1.0)).float().tolist()\n",
    "    var  = (running_m2   / torch.clamp(count, min=1.0)).float()\n",
    "    std  = torch.sqrt(torch.clamp(var, min=1e-12)).tolist()\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba332afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs res: (0.25, 0.25) Labels res: (0.25, 0.25)\n",
      "Inputs CRS: EPSG:4326 Labels CRS: EPSG:4326\n",
      "Bounds (intersection): BoundingBox(minx=-25.0, maxx=32.0, miny=32.25, maxy=81.0, mint=0.0, maxt=9.223372036854776e+18)\n",
      "[Info] Candidate windows (patch=64, stride=64): 16\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Build the paired dataset (inputs & labels) and window count\n",
    "inputs_ds = InputsDataset(args.in_dir)\n",
    "labels_ds = LabelsDataset(args.lab_dir)\n",
    "dataset   = inputs_ds & labels_ds\n",
    "\n",
    "# Show basic info\n",
    "print(\"Inputs res:\", inputs_ds.res, \"Labels res:\", labels_ds.res)\n",
    "print(\"Inputs CRS:\", inputs_ds.crs, \"Labels CRS:\", labels_ds.crs)\n",
    "print(\"Bounds (intersection):\", dataset.bounds)\n",
    "\n",
    "args.patch = 64  # was 256; must be <= the image min dimension (~195)\n",
    "\n",
    "# Count candidate windows using a non-overlapping grid\n",
    "from torchgeo.samplers import GridGeoSampler\n",
    "probe_stride = args.patch\n",
    "probe_grid   = GridGeoSampler(dataset, size=args.patch, stride=probe_stride)\n",
    "num_windows  = sum(1 for _ in probe_grid)\n",
    "print(f\"[Info] Candidate windows (patch={args.patch}, stride={probe_stride}): {num_windows}\")\n",
    "\n",
    "if num_windows == 0:\n",
    "    raise RuntimeError(\"No candidate windows at this patch size. Try args.patch = 128 and re-run this cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f69eace0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROIs set: \n",
      "  train xâˆˆ[-25.000,9.200] \n",
      "  val   xâˆˆ[9.200,20.600] \n",
      "  test  xâˆˆ[20.600,32.000]\n"
     ]
    }
   ],
   "source": [
    "# Define bounds for train/test/val splits\n",
    "from torchgeo.datasets import BoundingBox\n",
    "import math\n",
    "\n",
    "minx, maxx = dataset.bounds[0], dataset.bounds[1]\n",
    "miny, maxy = dataset.bounds[2], dataset.bounds[3]\n",
    "mint, maxt = float(\"-inf\"), float(\"inf\")\n",
    "\n",
    "# Split longitudinally into 60% / 20% / 20% (train / val / test)\n",
    "W = maxx - minx\n",
    "x1 = minx + 0.60 * W\n",
    "x2 = minx + 0.80 * W\n",
    "\n",
    "train_roi = BoundingBox(minx=minx, maxx=x1, miny=miny, maxy=maxy, mint=mint, maxt=maxt)\n",
    "val_roi   = BoundingBox(minx=x1,  maxx=x2, miny=miny, maxy=maxy, mint=mint, maxt=maxt)\n",
    "test_roi  = BoundingBox(minx=x2,  maxx=maxx,miny=miny, maxy=maxy, mint=mint, maxt=maxt)\n",
    "\n",
    "print(\"ROIs set:\",\n",
    "      f\"\\n  train xâˆˆ[{minx:.3f},{x1:.3f}]\",\n",
    "      f\"\\n  val   xâˆˆ[{x1:.3f},{x2:.3f}]\",\n",
    "      f\"\\n  test  xâˆˆ[{x2:.3f},{maxx:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa51d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samplers: Grid(train|val|test) with disjoint ROIs\n"
     ]
    }
   ],
   "source": [
    "from torchgeo.samplers import GridGeoSampler\n",
    "\n",
    "# Train: 50% overlap; Val/Test: no overlap\n",
    "train_sampler = GridGeoSampler(dataset, size=args.patch, stride=int(args.patch * 0.5), roi=train_roi)\n",
    "val_sampler   = GridGeoSampler(dataset, size=args.patch, stride=args.patch,                 roi=val_roi)\n",
    "test_sampler  = GridGeoSampler(dataset, size=args.patch, stride=args.patch,                 roi=test_roi)\n",
    "\n",
    "print(\"Samplers: Grid(train|val|test) with disjoint ROIs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ca3ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready (train/val/test).\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=args.batch, sampler=train_sampler,\n",
    "                          num_workers=args.workers, collate_fn=stack_samples,\n",
    "                          pin_memory=False, persistent_workers=False)\n",
    "val_loader   = DataLoader(dataset, batch_size=args.batch, sampler=val_sampler,\n",
    "                          num_workers=args.workers, collate_fn=stack_samples,\n",
    "                          pin_memory=False, persistent_workers=False)\n",
    "test_loader  = DataLoader(dataset, batch_size=args.batch, sampler=test_sampler,\n",
    "                          num_workers=args.workers, collate_fn=stack_samples,\n",
    "                          pin_memory=False, persistent_workers=False)\n",
    "\n",
    "print(\"DataLoaders ready (train/val/test).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3472bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['crs', 'bounds', 'image', 'mask'])\n",
      "X shape: torch.Size([4, 3, 64, 64]) Y shape: torch.Size([4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 â€” Smoke test a single batch\n",
    "sample = next(iter(train_loader))\n",
    "print(\"Keys:\", sample.keys())\n",
    "x0 = sample[\"image\"]              # (B, C, H, W)\n",
    "y0 = sample[\"mask\"]               # (B, H, W)\n",
    "print(\"X shape:\", x0.shape, \"Y shape:\", y0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d873f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 â€” Training function that accepts loaders (does NOT rebuild samplers/dataset)\n",
    "\n",
    "def run_with_loaders(args, train_loader, val_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # Peek for channels\n",
    "    sample = next(iter(train_loader))\n",
    "    x0 = sample[\"image\"]                    # (B,C,H,W)\n",
    "    y0 = sample[\"mask\"]                    # (B,H,W)\n",
    "    print(\"Sample keys:\", sample.keys())\n",
    "    print(\"X shape:\", x0.shape, \"Y shape:\", y0.shape)\n",
    "    in_ch = x0.shape[1]\n",
    "    print(f\"[Info] Inferred input channels: {in_ch}\")\n",
    "\n",
    "    # Normalization\n",
    "    if args.use_quick_norm:\n",
    "        mean, std = quick_channel_stats(train_loader, in_ch, args.norm_batches)\n",
    "    else:\n",
    "        mean = [0.0] * in_ch\n",
    "        std  = [1.0] * in_ch\n",
    "    normalize = ChannelWiseNormalize(mean, std).to(device)\n",
    "    print(f\"[Info] mean: {mean}\\n[Info] std : {std}\")\n",
    "\n",
    "    # Model\n",
    "    model = smp.Unet(\n",
    "        encoder_name=args.backbone,\n",
    "        encoder_weights=None,\n",
    "        in_channels=in_ch,\n",
    "        classes=1,\n",
    "        activation=None,\n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizer, loss, AMP\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                            optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "    criterion = MaskedHuber(delta=args.huber_delta)\n",
    "    scaler = torch.amp.GradScaler('cuda', enabled=args.amp)  # new API\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    bad_epochs = 0\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        # ---- Train\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        tr_n = 0\n",
    "        for batch in train_loader:\n",
    "            x = batch[\"image\"].float().to(device)\n",
    "            y = batch[\"mask\"].float().unsqueeze(1).to(device)  # (B,1,H,W)\n",
    "\n",
    "            # sanitize inputs; skip if no valid labels\n",
    "            x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).clamp(-1e6, 1e6)\n",
    "            if not torch.isfinite(y).any():\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=args.amp):\n",
    "                x = normalize(x)\n",
    "                yhat = torch.sigmoid(model(x))\n",
    "                loss = criterion(yhat, y)  # MaskedHuber ignores non-finite y\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)  # <-- unscale first\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            tr_n += 1\n",
    "\n",
    "        # ---- Validate\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        va_n = 0\n",
    "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=args.amp):\n",
    "            for batch in val_loader:\n",
    "                x = batch[\"image\"].float().to(device)\n",
    "                y = batch[\"mask\"].float().unsqueeze(1).to(device)\n",
    "                x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).clamp(-1e6, 1e6)\n",
    "                if not torch.isfinite(y).any():\n",
    "                    continue\n",
    "\n",
    "                x = normalize(x)\n",
    "                yhat = torch.sigmoid(model(x))\n",
    "                loss = criterion(yhat, y)\n",
    "                va_loss += loss.item()\n",
    "                va_n += 1\n",
    "\n",
    "        tr_loss = tr_loss / max(tr_n, 1)\n",
    "        va_loss = va_loss / max(va_n, 1)\n",
    "        print(f\"Epoch {epoch:03d} | train: {tr_loss:.4f} | val: {va_loss:.4f}\")\n",
    "\n",
    "        # Step scheduler on the actual validation loss\n",
    "        scheduler.step(va_loss if va_n > 0 else tr_loss)\n",
    "\n",
    "        if va_n > 0 and va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            ckpt = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"norm_mean\": getattr(normalize, \"mean\", None).flatten().tolist(),\n",
    "                \"norm_std\": getattr(normalize, \"std\", None).flatten().tolist(),\n",
    "                \"in_channels\": model.encoder.conv1.in_channels if hasattr(model.encoder, \"conv1\") else None,\n",
    "                \"backbone\": args.backbone,\n",
    "            }\n",
    "            Path(args.out_dir).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(ckpt, Path(args.out_dir) / \"best_unet_regression.pt\")\n",
    "            print(f\"  -> Saved best checkpoint (val={best_val:.4f})\")\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "            if bad_epochs >= 6:  # simple patience; align with scheduler patience if you want\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return model, normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eea98049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keys: dict_keys(['crs', 'bounds', 'image', 'mask'])\n",
      "X shape: torch.Size([4, 3, 64, 64]) Y shape: torch.Size([4, 64, 64])\n",
      "[Info] Inferred input channels: 3\n",
      "[Info] mean: [0.0, 0.0, 0.0]\n",
      "[Info] std : [1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_33540\\4275992405.py:37: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train: 0.0121 | val: 0.0402\n",
      "  -> Saved best checkpoint (val=0.0402)\n",
      "Epoch 002 | train: -0.0150 | val: -0.0245\n",
      "  -> Saved best checkpoint (val=-0.0245)\n",
      "Epoch 003 | train: -0.0370 | val: -0.0343\n",
      "  -> Saved best checkpoint (val=-0.0343)\n",
      "Epoch 004 | train: -0.0559 | val: -0.0605\n",
      "  -> Saved best checkpoint (val=-0.0605)\n",
      "Epoch 005 | train: -0.0709 | val: -0.0774\n",
      "  -> Saved best checkpoint (val=-0.0774)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 â€” Start training\n",
    "model, normalize = run_with_loaders(args, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64fcd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 â€” Eval helper (MAE, RMSE, R^2)\n",
    "def evaluate(loader, model, normalize, device):\n",
    "    model.eval()\n",
    "    mae_sum = rmse_sum = r2_sum = n = 0\n",
    "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
    "        for batch in loader:\n",
    "            x = batch[\"image\"].float().to(device)\n",
    "            y = batch[\"mask\"].float().unsqueeze(1).to(device)\n",
    "\n",
    "            # match training sanitization\n",
    "            x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).clamp(-1e6, 1e6)\n",
    "\n",
    "            m = torch.isfinite(y)\n",
    "            if not m.any():\n",
    "                continue\n",
    "\n",
    "            x = normalize(x)\n",
    "            p = torch.sigmoid(model(x))\n",
    "\n",
    "            yv, pv = y[m], p[m]\n",
    "            mae  = torch.mean(torch.abs(pv - yv)).item()\n",
    "            rmse = torch.sqrt(torch.mean((pv - yv)**2)).item()\n",
    "            ymean = torch.mean(yv)\n",
    "            denom = torch.sum((yv - ymean)**2).clamp_min(1e-12)\n",
    "            r2 = (1 - torch.sum((pv - yv)**2) / denom).item()\n",
    "\n",
    "            mae_sum += mae; rmse_sum += rmse; r2_sum += r2; n += 1\n",
    "    return mae_sum/max(n,1), rmse_sum/max(n,1), r2_sum/max(n,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_33540\\780099663.py:5: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation â†’ MAE nan | RMSE nan | RÂ² nan\n"
     ]
    }
   ],
   "source": [
    "# Cell 13 â€” Evaluate\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt = torch.load(Path(args.out_dir) / \"best_unet_regression.pt\", map_location=device)\n",
    "\n",
    "eval_model = smp.Unet(\n",
    "    encoder_name=args.backbone,\n",
    "    encoder_weights=None,\n",
    "    in_channels=ckpt[\"in_channels\"],    # multiband input\n",
    "    classes=1,\n",
    "    activation=None\n",
    ").to(device)\n",
    "eval_model.load_state_dict(ckpt[\"model_state\"])\n",
    "eval_norm = ChannelWiseNormalize(ckpt[\"norm_mean\"], ckpt[\"norm_std\"]).to(device)\n",
    "\n",
    "mae, rmse, r2 = evaluate(val_loader, eval_model, eval_norm, device)\n",
    "print(f\"Validation â†’ MAE {mae:.4f} | RMSE {rmse:.4f} | RÂ² {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b58bd986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST     â†’ MAE 0.0000 | RMSE 0.0000 | RÂ² 0.000\n"
     ]
    }
   ],
   "source": [
    "# Cell 14 â€” Final TEST evaluation\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Reuse the checkpoint and normalization already loaded in Cell 13\n",
    "test_mae, test_rmse, test_r2 = evaluate(test_loader, eval_model, eval_norm, device)\n",
    "print(f\"TEST     â†’ MAE {test_mae:.4f} | RMSE {test_rmse:.4f} | RÂ² {test_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71a979f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved QA figures to: C:\\Users\\Gebruiker\\Desktop\\Thesis\\FutureCISI-main\\empy_repo_for_thesis\\qa_figs\n"
     ]
    }
   ],
   "source": [
    "# Cell 15 â€” Save a few QA figures from val & test\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "qa_dir = Path(\"qa_figs\"); qa_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_triptychs(loader, tag, limit_batches=2):\n",
    "    eval_model.eval()\n",
    "    done = 0\n",
    "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
    "        for bidx, batch in enumerate(loader):\n",
    "            x = batch[\"image\"].float().to(device)\n",
    "            y = batch[\"mask\"].float().unsqueeze(1).to(device)\n",
    "            x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).clamp(-1e6, 1e6)\n",
    "\n",
    "            x = eval_norm(x)\n",
    "            p = torch.sigmoid(eval_model(x))\n",
    "\n",
    "            B = x.size(0); nshow = min(B, 4)\n",
    "            for i in range(nshow):\n",
    "                xi = x[i].detach().cpu()\n",
    "                yi = y[i,0].detach().cpu()\n",
    "                pi = p[i,0].detach().cpu()\n",
    "\n",
    "                # visualize first 3 channels (or repeat if 1)\n",
    "                rgb = xi.repeat(3,1,1) if xi.size(0)==1 else xi[:3]\n",
    "                rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min() + 1e-6)\n",
    "\n",
    "                fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "                axs[0].imshow(np.moveaxis(rgb.numpy(), 0, -1)); axs[0].set_title(\"Input\");   axs[0].axis(\"off\")\n",
    "                im1 = axs[1].imshow(yi.numpy(), vmin=0, vmax=1); axs[1].set_title(\"Target\"); axs[1].axis(\"off\")\n",
    "                im2 = axs[2].imshow(pi.numpy(), vmin=0, vmax=1); axs[2].set_title(\"Pred\");   axs[2].axis(\"off\")\n",
    "                fig.colorbar(im2, ax=axs, fraction=0.025, pad=0.02)\n",
    "                fig.tight_layout()\n",
    "                fig.savefig(qa_dir / f\"{tag}_b{bidx}_i{i}.png\", dpi=160)\n",
    "                plt.close(fig)\n",
    "\n",
    "            # prediction histogram for the batch\n",
    "            plt.figure(figsize=(5,4))\n",
    "            plt.hist(p.detach().cpu().numpy().ravel(), bins=50)\n",
    "            plt.title(f\"Pred histogram â€” {tag} batch {bidx}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(qa_dir / f\"{tag}_b{bidx}_hist.png\", dpi=160)\n",
    "            plt.close()\n",
    "\n",
    "            done += 1\n",
    "            if done >= limit_batches:\n",
    "                break\n",
    "\n",
    "save_triptychs(val_loader,  tag=\"val\",  limit_batches=2)\n",
    "save_triptychs(test_loader, tag=\"test\", limit_batches=2)\n",
    "print(f\"Saved QA figures to: {qa_dir.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f94d1b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'model_state', 'optimizer_state', 'norm_mean', 'norm_std', 'in_channels', 'backbone'])\n"
     ]
    }
   ],
   "source": [
    "# Check out checkpoint\n",
    "import torch\n",
    "checkpoint = torch.load(\"checkpoints/best_unet_regression.pt\", map_location=\"cpu\")\n",
    "print(checkpoint.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6305de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16 â€” Full-area inference present-day to GeoTIFF\n",
    "import os, glob, math\n",
    "from pathlib import Path\n",
    "import numpy as np, torch, rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt_path = Path(args.out_dir) / \"best_unet_regression.pt\"\n",
    "out_dir   = Path(\"outputs\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Locate the present-day predictor raster (multiband file)\n",
    "pred_paths = glob.glob(str(Path(args.in_dir) / \"historic_3band_025deg.tif\"))\n",
    "assert len(pred_paths) == 1, f\"Expected exactly one present-day predictor file, found: {pred_paths}\"\n",
    "pred_path = pred_paths[0]\n",
    "\n",
    "# 2) Restore model + normalization from checkpoint\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "eval_model = smp.Unet(\n",
    "    encoder_name=ckpt[\"backbone\"],\n",
    "    encoder_weights=None,\n",
    "    in_channels=ckpt[\"in_channels\"],\n",
    "    classes=1,\n",
    "    activation=None\n",
    ").to(device)\n",
    "eval_model.load_state_dict(ckpt[\"model_state\"])\n",
    "eval_model.eval()\n",
    "eval_norm = ChannelWiseNormalize(ckpt[\"norm_mean\"], ckpt[\"norm_std\"]).to(device)\n",
    "\n",
    "# 3) Sliding-window inference with overlap-averaging\n",
    "PATCH  = args.patch                 # same as training (e.g., 64)\n",
    "STRIDE = max(1, int(PATCH // 2))    # 50% overlap like training\n",
    "\n",
    "with rasterio.open(pred_path, \"r\") as src:\n",
    "    H, W = src.height, src.width\n",
    "    C = src.count\n",
    "    profile = src.profile.copy()\n",
    "    profile.update(count=1, dtype=\"float32\", nodata=np.nan, compress=\"lzw\")\n",
    "\n",
    "    pred_sum   = np.zeros((H, W), dtype=np.float64)\n",
    "    pred_count = np.zeros((H, W), dtype=np.float64)\n",
    "\n",
    "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
    "        for top in range(0, H, STRIDE):\n",
    "            for left in range(0, W, STRIDE):\n",
    "                h = min(PATCH, H - top)\n",
    "                w = min(PATCH, W - left)\n",
    "                if h <= 0 or w <= 0:\n",
    "                    continue\n",
    "\n",
    "                # read window (C,H,W)\n",
    "                win = Window(left, top, w, h)\n",
    "                x_np = src.read(indexes=list(range(1, C+1)), window=win, out_dtype=\"float32\")  # (C,h,w)\n",
    "\n",
    "                # skip if totally nodata\n",
    "                if not np.isfinite(x_np).any():\n",
    "                    continue\n",
    "\n",
    "                x = torch.from_numpy(x_np[None, ...])  # (1,C,h,w)\n",
    "                x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).clamp(-1e6, 1e6).to(device)\n",
    "                x = eval_norm(x)\n",
    "                p = torch.sigmoid(eval_model(x)).float().detach().cpu().numpy()  # (1,1,h,w)\n",
    "                p = p[0, 0]\n",
    "\n",
    "                # accumulate\n",
    "                pred_sum[top:top+h, left:left+w]   += p\n",
    "                pred_count[top:top+h, left:left+w] += 1.0\n",
    "\n",
    "    # 4) finalize (average where we predicted, NaN elsewhere)\n",
    "    out = np.full((H, W), np.nan, dtype=np.float32)\n",
    "    m = pred_count > 0\n",
    "    out[m] = (pred_sum[m] / pred_count[m]).astype(np.float32)\n",
    "\n",
    "    out_path = out_dir / \"cisi_pred_present_025deg.tif\"\n",
    "    with rasterio.open(out_path, \"w\", **profile) as dst:\n",
    "        dst.write(out, 1)\n",
    "\n",
    "print(f\"Wrote present-day prediction to: {out_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f27e05e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Missing 2030 predictors: READY_data\\inputs\\scenario_2030_3band_025deg.tif",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 1) SET THIS to your 2030 multiband predictors on the same grid (0.25Â°, same band order)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m pred_2030_path \u001b[38;5;241m=\u001b[39m Path(args\u001b[38;5;241m.\u001b[39min_dir) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscenario_2030_3band_025deg.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m pred_2030_path\u001b[38;5;241m.\u001b[39mexists(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing 2030 predictors: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_2030_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 2) Restore model + normalization\u001b[39;00m\n\u001b[0;32m     16\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(ckpt_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Missing 2030 predictors: READY_data\\inputs\\scenario_2030_3band_025deg.tif"
     ]
    }
   ],
   "source": [
    "# Cell 17 â€” 2030 scenario inference â†’ GeoTIFF\n",
    "import os, rasterio\n",
    "from rasterio.windows import Window\n",
    "from pathlib import Path\n",
    "import numpy as np, torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt_path = Path(args.out_dir) / \"best_unet_regression.pt\"\n",
    "out_dir   = Path(\"outputs\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) SET THIS to your 2030 multiband predictors on the same grid (0.25Â°, same band order)\n",
    "pred_2030_path = Path(args.in_dir) / \"scenario_2030_3band_025deg.tif\"\n",
    "assert pred_2030_path.exists(), f\"Missing 2030 predictors: {pred_2030_path}\"\n",
    "\n",
    "# 2) Restore model + normalization\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\")\n",
    "eval_model = smp.Unet(\n",
    "    encoder_name=ckpt[\"backbone\"],\n",
    "    encoder_weights=None,\n",
    "    in_channels=ckpt[\"in_channels\"],\n",
    "    classes=1,\n",
    "    activation=None\n",
    ").to(device)\n",
    "eval_model.load_state_dict(ckpt[\"model_state\"])\n",
    "eval_model.eval()\n",
    "eval_norm = ChannelWiseNormalize(ckpt[\"norm_mean\"], ckpt[\"norm_std\"]).to(device)\n",
    "\n",
    "# 3) Slide + stitch (same PATCH/STRIDE)\n",
    "PATCH  = args.patch\n",
    "STRIDE = max(1, int(PATCH // 2))\n",
    "\n",
    "with rasterio.open(pred_2030_path, \"r\") as src:\n",
    "    H, W = src.height, src.width\n",
    "    C = src.count\n",
    "    profile = src.profile.copy()\n",
    "    profile.update(count=1, dtype=\"float32\", nodata=np.nan, compress=\"lzw\")\n",
    "\n",
    "    pred_sum   = np.zeros((H, W), dtype=np.float64)\n",
    "    pred_count = np.zeros((H, W), dtype=np.float64)\n",
    "\n",
    "    with torch.no_grad(), torch.amp.autocast('cuda', enabled=(device=='cuda')):\n",
    "        for top in range(0, H, STRIDE):\n",
    "            for left in range(0, W, STRIDE):\n",
    "                h = min(PATCH, H - top)\n",
    "                w = min(PATCH, W - left)\n",
    "                if h <= 0 or w <= 0:\n",
    "                    continue\n",
    "\n",
    "                win = Window(left, top, w, h)\n",
    "                x_np = src.read(indexes=list(range(1, C+1)), window=win, out_dtype=\"float32\")\n",
    "                if not np.isfinite(x_np).any():\n",
    "                    continue\n",
    "\n",
    "                x = torch.from_numpy(x_np[None, ...])  # (1,C,h,w)\n",
    "                x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).clamp(-1e6, 1e6).to(device)\n",
    "                x = eval_norm(x)\n",
    "                p = torch.sigmoid(eval_model(x)).float().detach().cpu().numpy()  # (1,1,h,w)\n",
    "                p = p[0, 0]\n",
    "\n",
    "                pred_sum[top:top+h, left:left+w]   += p\n",
    "                pred_count[top:top+h, left:left+w] += 1.0\n",
    "\n",
    "    out = np.full((H, W), np.nan, dtype=np.float32)\n",
    "    m = pred_count > 0\n",
    "    out[m] = (pred_sum[m] / pred_count[m]).astype(np.float32)\n",
    "\n",
    "    out_2030_path = out_dir / \"cisi_pred_2030_025deg.tif\"\n",
    "    with rasterio.open(out_2030_path, \"w\", **profile) as dst:\n",
    "        dst.write(out, 1)\n",
    "\n",
    "print(f\"Wrote 2030 prediction to: {out_2030_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db2f30c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: C:\\Users\\Gebruiker\\Desktop\\Thesis\\FutureCISI-main\\empy_repo_for_thesis\\outputs\\config.json\n",
      "Wrote: C:\\Users\\Gebruiker\\Desktop\\Thesis\\FutureCISI-main\\empy_repo_for_thesis\\outputs\\metrics.json\n",
      "Wrote: C:\\Users\\Gebruiker\\Desktop\\Thesis\\FutureCISI-main\\empy_repo_for_thesis\\outputs\\MANIFEST.txt\n"
     ]
    }
   ],
   "source": [
    "# Cell 18 â€” Package artifacts (config, metrics, manifest)\n",
    "import json, datetime\n",
    "from pathlib import Path\n",
    "\n",
    "pack_dir = Path(\"outputs\"); pack_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Config snapshot\n",
    "config = {\n",
    "    \"timestamp\": datetime.datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"grid\": {\"crs\": \"EPSG:4326\", \"resolution_deg\": 0.25},\n",
    "    \"data\": {\n",
    "        \"inputs\": \"READY_data/inputs/historic_3band_025deg.tif\",\n",
    "        \"label\":  \"READY_data/labels/2024_CISI_025deg.tif\",\n",
    "        \"scenario_2030\": \"READY_data/inputs/scenario_2030_3band_025deg.tif\"\n",
    "    },\n",
    "    \"splits\": {\n",
    "        \"train_val_test_split\": \"longitudinal 60/20/20 via BoundingBox ROIs\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"arch\": \"smp.Unet\",\n",
    "        \"backbone\": args.backbone,\n",
    "        \"in_channels\": int(ckpt[\"in_channels\"]) if \"ckpt\" in globals() else \"see checkpoint\",\n",
    "        \"classes\": 1,\n",
    "        \"activation\": \"external sigmoid\"\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"patch\": args.patch,\n",
    "        \"batch\": args.batch,\n",
    "        \"epochs\": args.epochs,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"lr\": args.lr,\n",
    "        \"weight_decay\": args.wd,\n",
    "        \"loss\": f\"MaskedHuber(delta={args.huber_delta})\",\n",
    "        \"amp\": bool(args.amp),\n",
    "        \"grad_clip_norm\": 1.0,\n",
    "        \"scheduler\": \"ReduceLROnPlateau(factor=0.5, patience=3)\",\n",
    "        \"early_stopping_patience\": 6\n",
    "    },\n",
    "    \"normalization\": {\n",
    "        \"train_only_mean\": \"saved in checkpoint\",\n",
    "        \"train_only_std\":  \"saved in checkpoint\"\n",
    "    },\n",
    "    \"artifacts\": {\n",
    "        \"checkpoint\": str(Path(args.out_dir) / \"best_unet_regression.pt\"),\n",
    "        \"present_day_tif\": str(Path(\"outputs\") / \"cisi_pred_present_025deg.tif\"),\n",
    "        \"cisi_2030_tif\":   str(Path(\"outputs\") / \"cisi_pred_2030_025deg.tif\"),\n",
    "        \"qa_figs_dir\":     \"qa_figs\"\n",
    "    }\n",
    "}\n",
    "with open(pack_dir / \"config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "# 2) Metrics snapshot (if variables exist; otherwise you can re-run evaluate)\n",
    "metrics = {}\n",
    "if \"mae\" in globals():\n",
    "    metrics[\"val\"] = {\"mae\": float(mae), \"rmse\": float(rmse), \"r2\": float(r2)}\n",
    "if \"test_mae\" in globals():\n",
    "    metrics[\"test\"] = {\"mae\": float(test_mae), \"rmse\": float(test_rmse), \"r2\": float(test_r2)}\n",
    "with open(pack_dir / \"metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "# 3) Manifest (plain text summary)\n",
    "manifest = f\"\"\"Thesis Model Artifacts\n",
    "========================\n",
    "Checkpoint: {config['artifacts']['checkpoint']}\n",
    "Present-day GeoTIFF: {config['artifacts']['present_day_tif']}\n",
    "2030 GeoTIFF: {config['artifacts']['cisi_2030_tif']}\n",
    "QA Figures: {config['artifacts']['qa_figs_dir']}\n",
    "\n",
    "Metrics:\n",
    "- Val:  {metrics.get('val', {})}\n",
    "- Test: {metrics.get('test', {})}\n",
    "\"\"\"\n",
    "with open(pack_dir / \"MANIFEST.txt\", \"w\") as f:\n",
    "    f.write(manifest)\n",
    "\n",
    "print(\"Wrote:\", (pack_dir / \"config.json\").resolve())\n",
    "print(\"Wrote:\", (pack_dir / \"metrics.json\").resolve())\n",
    "print(\"Wrote:\", (pack_dir / \"MANIFEST.txt\").resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6cd20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
