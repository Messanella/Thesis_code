{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8eaa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: torchgeo in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: rasterio in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: segmentation-models-pytorch in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: albumentations in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.8)\n",
      "Requirement already satisfied: filelock in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: einops>=0.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (0.8.1)\n",
      "Requirement already satisfied: fiona>=1.8.22 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.10.1)\n",
      "Requirement already satisfied: kornia>=0.7.4 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (0.8.1)\n",
      "Requirement already satisfied: lightly!=1.4.26,>=1.4.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.5.21)\n",
      "Requirement already satisfied: lightning!=2.3.*,!=2.5.0,>=2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.5.1.post0)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (3.8.4)\n",
      "Requirement already satisfied: pandas>=1.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (2.3.3)\n",
      "Requirement already satisfied: pyproj>=3.4 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (3.7.1)\n",
      "Requirement already satisfied: rtree>=1.0.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.4.0)\n",
      "Requirement already satisfied: shapely>=1.8.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (2.0.7)\n",
      "Requirement already satisfied: timm>=0.9.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.0.15)\n",
      "Requirement already satisfied: torchmetrics>=1.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchgeo) (1.7.2)\n",
      "Requirement already satisfied: affine in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (23.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (2024.6.2)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: click-plugins in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rasterio) (3.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (0.33.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from segmentation-models-pytorch) (4.66.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations) (1.13.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations) (2.11.6)\n",
      "Requirement already satisfied: albucore==0.0.24 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albucore==0.0.24->albumentations) (4.2.1)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from click>=4.0->rasterio) (0.4.6)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (24.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\n",
      "Requirement already satisfied: kornia_rs>=0.1.9 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from kornia>=0.7.4->torchgeo) (0.1.9)\n",
      "Requirement already satisfied: hydra-core>=1.0.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (1.3.2)\n",
      "Requirement already satisfied: lightly_utils~=0.0.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (0.0.2)\n",
      "Requirement already satisfied: python_dateutil>=2.5.3 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (1.16.0)\n",
      "Requirement already satisfied: pytorch_lightning>=1.0.4 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.5.1.post0)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (2.2.2)\n",
      "Requirement already satisfied: aenum>=3.1.11 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightly!=1.4.26,>=1.4.5->torchgeo) (3.1.16)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.14.3)\n",
      "Requirement already satisfied: jsonargparse<5.0,>=4.27.7 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (4.40.0)\n",
      "Requirement already satisfied: omegaconf<3.0,>=2.2.3 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.3.0)\n",
      "Requirement already satisfied: rich<14.0,>=12.3.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (13.7.1)\n",
      "Requirement already satisfied: tensorboardX<3.0,>=2.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.6.4)\n",
      "Requirement already satisfied: bitsandbytes<1.0,>=0.45.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.46.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.6->torchgeo) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.6->torchgeo) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.6->torchgeo) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>=3.6->torchgeo) (1.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.5->torchgeo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.5->torchgeo) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (3.12.12)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hydra-core>=1.0.0->lightly!=1.4.26,>=1.4.5->torchgeo) (4.9.3)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.16)\n",
      "Requirement already satisfied: typeshed-client>=2.3.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from lightning-utilities<2.0,>=0.10.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (70.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.7)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gebruiker\\appdata\\roaming\\python\\python311\\site-packages (from rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.17.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboardX<3.0,>=2.2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (5.29.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning!=2.3.*,!=2.5.0,>=2->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (1.20.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0,>=12.3.0->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (0.1.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in c:\\users\\gebruiker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typeshed-client>=2.3.0->jsonargparse[signatures]<5.0,>=4.27.7; extra == \"pytorch-extra\"->lightning[pytorch-extra]!=2.3.*,!=2.5.0,>=2->torchgeo) (6.5.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# installing\n",
    "!pip install torch torchvision torchgeo rasterio segmentation-models-pytorch albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "434fa2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TorchGeo imports\n",
    "from torchgeo.datasets import RasterDataset\n",
    "try:\n",
    "    from torchgeo.datasets import stack_samples  # newer\n",
    "except Exception:\n",
    "    from torchgeo.datasets.utils import stack_samples  # older\n",
    "\n",
    "try:\n",
    "    from torchgeo.datasets.geo import IntersectionDataset\n",
    "except Exception:\n",
    "    from torchgeo.datasets import IntersectionDataset\n",
    "\n",
    "from torchgeo.samplers import GridGeoSampler, RandomGeoSampler\n",
    "\n",
    "# U-Net backbone (Segmentation Models PyTorch)\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8adb70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # stack three single-band rasters into one 3-band GeoTIFF\n",
    "# in_dir  = Path(\"READY_data/inputs\")\n",
    "# out_mb  = in_dir / \"historic_3band_025deg.tif\"\n",
    "\n",
    "# in_lc   = in_dir / \"2018_landcover_aligned_025deg.tif\"\n",
    "# in_gdp  = in_dir / \"2019_gdp_aligned_025deg.tif\"\n",
    "# in_pop  = in_dir / \"2020_pop_aligned_025deg.tif\"\n",
    "\n",
    "# with rasterio.open(in_lc) as src_lc, \\\n",
    "#      rasterio.open(in_gdp) as src_gdp, \\\n",
    "#      rasterio.open(in_pop) as src_pop:\n",
    "\n",
    "#     # sanity checks\n",
    "#     assert src_lc.crs == src_gdp.crs == src_pop.crs, \"CRS mismatch\"\n",
    "#     assert src_lc.transform == src_gdp.transform == src_pop.transform, \"transform mismatch\"\n",
    "#     assert (src_lc.width, src_lc.height) == (src_gdp.width, src_gdp.height) == (src_pop.width, src_pop.height), \"size mismatch\"\n",
    "\n",
    "#     lc  = src_lc.read(1)\n",
    "#     gdp = src_gdp.read(1)\n",
    "#     pop = src_pop.read(1)\n",
    "\n",
    "#     arr = np.stack([lc, gdp, pop], axis=0).astype(np.float32)  # (3, H, W)\n",
    "\n",
    "#     profile = src_lc.profile\n",
    "#     profile.update(count=3, dtype=\"float32\", nodata=np.nan)\n",
    "\n",
    "#     with rasterio.open(out_mb, \"w\", **profile) as dst:\n",
    "#         dst.write(arr)\n",
    "#         dst.set_band_description(1, \"landcover\")\n",
    "#         dst.set_band_description(2, \"gdp\")\n",
    "#         dst.set_band_description(3, \"pop\")\n",
    "\n",
    "# print(\"Wrote:\", out_mb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "573a0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick inspection\n",
    "# import rasterio\n",
    "# from pathlib import Path\n",
    "\n",
    "# path = Path(\"READY_data/inputs/historic_3band_025deg.tif\")\n",
    "# with rasterio.open(path) as src:\n",
    "#     print(\"Bands:\", src.count)            # expect 3\n",
    "#     print(\"Size :\", src.width, \"x\", src.height)\n",
    "#     print(\"CRS  :\", src.crs)\n",
    "#     print(\"Desc :\", src.descriptions)     # ('landcover','gdp','pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "77fa0211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "class Args:\n",
    "    pass\n",
    "\n",
    "args = Args()\n",
    "args.in_dir = \"READY_data/inputs\"\n",
    "args.lab_dir = \"READY_data/labels\"\n",
    "args.out_dir = \"checkpoints\"\n",
    "\n",
    "args.patch = 64\n",
    "args.train_windows = 500\n",
    "args.val_stride_frac = 1.0\n",
    "args.batch = 4\n",
    "args.workers = 0\n",
    "\n",
    "args.epochs = 5\n",
    "args.lr = 3e-4\n",
    "args.wd = 1e-2\n",
    "args.huber_delta = 0.5\n",
    "args.backbone = \"resnet34\"\n",
    "args.amp = True\n",
    "\n",
    "# ðŸ‘‡ add this line to fix the NaN normalization issue\n",
    "args.use_quick_norm = False\n",
    "args.norm_batches = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "2cc217e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "class InputsDataset(RasterDataset):\n",
    "    \"\"\"Multi-band inputs (e.g., population, GDP, land-use) as aligned GeoTIFFs.\"\"\"\n",
    "    filename_glob = \"historic_3band_025deg.tif\"  # <â€” only the multiband file\n",
    "    is_image = True\n",
    "\n",
    "class LabelsDataset(RasterDataset):\n",
    "    \"\"\"\n",
    "    Single-band continuous target (e.g., CISI scaled to [0,1]).\n",
    "    Use float32 for continuous targets.\n",
    "    \"\"\"\n",
    "    filename_glob = \"2024_CISI_025deg.tif\"   # your label stays as before (single band)\n",
    "    is_image = False\n",
    "    dtype = torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "20036813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization & Loss\n",
    "class ChannelWiseNormalize(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super().__init__()\n",
    "        m = torch.as_tensor(mean).view(1, -1, 1, 1)\n",
    "        s = torch.as_tensor(std).view(1, -1, 1, 1)\n",
    "        self.register_buffer(\"mean\", m.float())\n",
    "        self.register_buffer(\"std\", s.float())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "\n",
    "class MaskedHuber(nn.Module):\n",
    "    \"\"\"Huber regression loss that ignores NaN or masked values.\"\"\"\n",
    "    def __init__(self, delta=0.5):\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def forward(self, pred, target, mask=None):\n",
    "        if mask is None:\n",
    "            mask = torch.isfinite(target)\n",
    "        mask = mask.float()\n",
    "\n",
    "        diff = pred - target\n",
    "        abs_diff = diff.abs()\n",
    "        delta = torch.tensor(self.delta, device=pred.device)\n",
    "        quadratic = torch.minimum(abs_diff, delta)\n",
    "        loss = 0.5 * quadratic**2 + delta * (abs_diff - quadratic) - 0.5 * (delta**2)\n",
    "        loss = loss * mask\n",
    "        denom = mask.sum().clamp_min(1.0)\n",
    "        return loss.sum() / denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "53c49b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def quick_channel_stats(train_loader, in_ch, norm_batches):\n",
    "    \"\"\"Rough channel-wise mean/std over a few batches.\"\"\"\n",
    "    running_mean = torch.zeros(in_ch, dtype=torch.float64)\n",
    "    running_var = torch.zeros(in_ch, dtype=torch.float64)\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            xb = batch[\"image\"].float()  # (B,C,H,W)\n",
    "            B, C, H, W = xb.shape\n",
    "            xb = xb.view(B, C, -1)\n",
    "            running_mean += xb.mean(dim=(0, 2)).double()\n",
    "            running_var += xb.var(dim=(0, 2), unbiased=False).double()\n",
    "            n += 1\n",
    "            if i + 1 >= norm_batches:\n",
    "                break\n",
    "    mean = (running_mean / max(n, 1)).float().tolist()\n",
    "    std = (running_var / max(n, 1)).sqrt().float().tolist()\n",
    "    return mean, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ba332afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs res: (0.25, 0.25) Labels res: (0.25, 0.25)\n",
      "Inputs CRS: EPSG:4326 Labels CRS: EPSG:4326\n",
      "Bounds (intersection): BoundingBox(minx=-25.0, maxx=32.0, miny=32.25, maxy=81.0, mint=0.0, maxt=9.223372036854776e+18)\n",
      "[Info] Candidate windows (patch=64, stride=64): 16\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Build the paired dataset (inputs & labels) and window count\n",
    "inputs_ds = InputsDataset(args.in_dir)\n",
    "labels_ds = LabelsDataset(args.lab_dir)\n",
    "dataset   = inputs_ds & labels_ds\n",
    "\n",
    "# Show basic info\n",
    "print(\"Inputs res:\", inputs_ds.res, \"Labels res:\", labels_ds.res)\n",
    "print(\"Inputs CRS:\", inputs_ds.crs, \"Labels CRS:\", labels_ds.crs)\n",
    "print(\"Bounds (intersection):\", dataset.bounds)\n",
    "\n",
    "args.patch = 64  # was 256; must be <= the image min dimension (~195)\n",
    "\n",
    "# Count candidate windows using a non-overlapping grid\n",
    "from torchgeo.samplers import GridGeoSampler\n",
    "probe_stride = args.patch\n",
    "probe_grid   = GridGeoSampler(dataset, size=args.patch, stride=probe_stride)\n",
    "num_windows  = sum(1 for _ in probe_grid)\n",
    "print(f\"[Info] Candidate windows (patch={args.patch}, stride={probe_stride}): {num_windows}\")\n",
    "\n",
    "if num_windows == 0:\n",
    "    raise RuntimeError(\"No candidate windows at this patch size. Try args.patch = 128 and re-run this cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aa51d5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samplers: Grid(train), Grid(val)\n"
     ]
    }
   ],
   "source": [
    "# Samplers\n",
    "from torchgeo.samplers import GridGeoSampler, RandomGeoSampler\n",
    "\n",
    "# Choose ONE of these two options \n",
    "\n",
    "# grid\n",
    "train_sampler = GridGeoSampler(dataset, size=args.patch, stride=int(args.patch * 0.5))  # 50% overlap\n",
    "val_sampler   = GridGeoSampler(dataset, size=args.patch, stride=args.patch)             # no overlap\n",
    "print(\"Samplers: Grid(train), Grid(val)\")\n",
    "\n",
    "# random sampling\n",
    "# safe_train_windows = min(args.train_windows, num_windows)\n",
    "# print(f\"Using RandomGeoSampler length={safe_train_windows} (available={num_windows})\")\n",
    "# train_sampler = RandomGeoSampler(dataset, size=args.patch, length=safe_train_windows)\n",
    "# val_sampler   = GridGeoSampler(dataset, size=args.patch, stride=args.patch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5ca3ee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders ready.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 â€” Build DataLoaders (uses the train_sampler / val_sampler you defined above)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset, batch_size=args.batch, sampler=train_sampler,\n",
    "    num_workers=0, collate_fn=stack_samples,\n",
    "    pin_memory=False, persistent_workers=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset, batch_size=args.batch, sampler=val_sampler,\n",
    "    num_workers=0, collate_fn=stack_samples,\n",
    "    pin_memory=False, persistent_workers=False\n",
    ")\n",
    "print(\"DataLoaders ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3472bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['crs', 'bounds', 'image', 'mask'])\n",
      "X shape: torch.Size([4, 3, 64, 64]) Y shape: torch.Size([4, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Cell 9 â€” Smoke test a single batch\n",
    "sample = next(iter(train_loader))\n",
    "print(\"Keys:\", sample.keys())\n",
    "x0 = sample[\"image\"]              # (B, C, H, W)\n",
    "y0 = sample[\"mask\"]               # (B, H, W)\n",
    "print(\"X shape:\", x0.shape, \"Y shape:\", y0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d873f9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10 â€” Training function that accepts loaders (does NOT rebuild samplers/dataset)\n",
    "\n",
    "def run_with_loaders(args, train_loader, val_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # Peek for channels\n",
    "    sample = next(iter(train_loader))\n",
    "    x0 = sample[\"image\"]                    # (B,C,H,W)\n",
    "    y0 = sample[\"mask\"]                    # (B,H,W)\n",
    "    print(\"Sample keys:\", sample.keys())\n",
    "    print(\"X shape:\", x0.shape, \"Y shape:\", y0.shape)\n",
    "    in_ch = x0.shape[1]\n",
    "    print(f\"[Info] Inferred input channels: {in_ch}\")\n",
    "\n",
    "    # Normalization\n",
    "    if args.use_quick_norm:\n",
    "        mean, std = quick_channel_stats(train_loader, in_ch, args.norm_batches)\n",
    "    else:\n",
    "        mean = [0.0] * in_ch\n",
    "        std  = [1.0] * in_ch\n",
    "    normalize = ChannelWiseNormalize(mean, std).to(device)\n",
    "    print(f\"[Info] mean: {mean}\\n[Info] std : {std}\")\n",
    "\n",
    "    # Model\n",
    "    model = smp.Unet(\n",
    "        encoder_name=args.backbone,\n",
    "        encoder_weights=None,\n",
    "        in_channels=in_ch,\n",
    "        classes=1,\n",
    "        activation=None,\n",
    "    ).to(device)\n",
    "\n",
    "    # Optimizer, loss, AMP\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.wd)\n",
    "    criterion = MaskedHuber(delta=args.huber_delta)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=args.amp)\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        # ---- Train\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        tr_n = 0\n",
    "        for batch in train_loader:\n",
    "            x = batch[\"image\"].float().to(device)\n",
    "            y = batch[\"mask\"].float().unsqueeze(1).to(device)  # (B,1,H,W)\n",
    "\n",
    "            # sanitize inputs; skip if no valid labels\n",
    "            x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).clamp(-1e6, 1e6)\n",
    "            if not torch.isfinite(y).any():\n",
    "                continue\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.amp.autocast('cuda', enabled=args.amp):\n",
    "                x = normalize(x)\n",
    "                yhat = torch.sigmoid(model(x))\n",
    "                loss = criterion(yhat, y)  # MaskedHuber ignores non-finite y\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            tr_n += 1\n",
    "\n",
    "        # ---- Validate\n",
    "        model.eval()\n",
    "        va_loss = 0.0\n",
    "        va_n = 0\n",
    "        with torch.no_grad(), torch.amp.autocast('cuda', enabled=args.amp):\n",
    "            for batch in val_loader:\n",
    "                x = batch[\"image\"].float().to(device)\n",
    "                y = batch[\"mask\"].float().unsqueeze(1).to(device)\n",
    "                x = torch.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0).clamp(-1e6, 1e6)\n",
    "                if not torch.isfinite(y).any():\n",
    "                    continue\n",
    "\n",
    "                x = normalize(x)\n",
    "                yhat = torch.sigmoid(model(x))\n",
    "                loss = criterion(yhat, y)\n",
    "                va_loss += loss.item()\n",
    "                va_n += 1\n",
    "\n",
    "        tr_loss = tr_loss / max(tr_n, 1)\n",
    "        va_loss = va_loss / max(va_n, 1)\n",
    "        print(f\"Epoch {epoch:03d} | train: {tr_loss:.4f} | val: {va_loss:.4f}\")\n",
    "\n",
    "        if va_n > 0 and va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            ckpt = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"norm_mean\": getattr(normalize, \"mean\", None).flatten().tolist(),\n",
    "                \"norm_std\": getattr(normalize, \"std\", None).flatten().tolist(),\n",
    "                \"in_channels\": model.encoder.conv1.in_channels if hasattr(model.encoder, \"conv1\") else None,\n",
    "                \"backbone\": args.backbone,\n",
    "            }\n",
    "            Path(args.out_dir).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(ckpt, Path(args.out_dir) / \"best_unet_regression.pt\")\n",
    "            print(f\"  -> Saved best checkpoint (val={best_val:.4f})\")\n",
    "\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return model, normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "eea98049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample keys: dict_keys(['crs', 'bounds', 'image', 'mask'])\n",
      "X shape: torch.Size([4, 3, 64, 64]) Y shape: torch.Size([4, 64, 64])\n",
      "[Info] Inferred input channels: 3\n",
      "[Info] mean: [0.0, 0.0, 0.0]\n",
      "[Info] std : [1.0, 1.0, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_9320\\4275992405.py:37: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train: -0.0437 | val: -0.0664\n",
      "  -> Saved best checkpoint (val=-0.0664)\n",
      "Epoch 002 | train: -0.0716 | val: -0.0860\n",
      "  -> Saved best checkpoint (val=-0.0860)\n",
      "Epoch 003 | train: -0.0882 | val: -0.0952\n",
      "  -> Saved best checkpoint (val=-0.0952)\n",
      "Epoch 004 | train: -0.0990 | val: -0.1025\n",
      "  -> Saved best checkpoint (val=-0.1025)\n",
      "Epoch 005 | train: -0.1062 | val: -0.1084\n",
      "  -> Saved best checkpoint (val=-0.1084)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Cell 11 â€” Start training\n",
    "model, normalize = run_with_loaders(args, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "64fcd3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12 â€” Eval helper (MAE, RMSE, R^2)\n",
    "def evaluate(loader, model, normalize, device):\n",
    "    model.eval()\n",
    "    mae_sum = rmse_sum = r2_sum = n = 0\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        for batch in loader:\n",
    "            x = batch[\"image\"].float().to(device)\n",
    "            y = batch[\"mask\"].float().unsqueeze(1).to(device)\n",
    "            m = torch.isfinite(y)\n",
    "            if not m.any():\n",
    "                continue\n",
    "            x = normalize(x)\n",
    "            p = torch.sigmoid(model(x))\n",
    "            yv, pv = y[m], p[m]\n",
    "            mae  = torch.mean(torch.abs(pv - yv)).item()\n",
    "            rmse = torch.sqrt(torch.mean((pv - yv)**2)).item()\n",
    "            ymean = torch.mean(yv)\n",
    "            r2 = (1 - torch.sum((pv - yv)**2) / torch.sum((yv - ymean)**2).clamp_min(1e-12)).item()\n",
    "            mae_sum += mae; rmse_sum += rmse; r2_sum += r2; n += 1\n",
    "    return mae_sum/max(n,1), rmse_sum/max(n,1), r2_sum/max(n,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "01d2ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_9320\\780099663.py:5: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.no_grad(), torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation â†’ MAE nan | RMSE nan | RÂ² nan\n"
     ]
    }
   ],
   "source": [
    "# Cell 13 â€” Evaluate\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ckpt = torch.load(Path(args.out_dir) / \"best_unet_regression.pt\", map_location=device)\n",
    "\n",
    "eval_model = smp.Unet(\n",
    "    encoder_name=args.backbone,\n",
    "    encoder_weights=None,\n",
    "    in_channels=3,    # multiband input\n",
    "    classes=1,\n",
    "    activation=None\n",
    ").to(device)\n",
    "eval_model.load_state_dict(ckpt[\"model_state\"])\n",
    "eval_norm = ChannelWiseNormalize(ckpt[\"norm_mean\"], ckpt[\"norm_std\"]).to(device)\n",
    "\n",
    "mae, rmse, r2 = evaluate(val_loader, eval_model, eval_norm, device)\n",
    "print(f\"Validation â†’ MAE {mae:.4f} | RMSE {rmse:.4f} | RÂ² {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94d1b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
